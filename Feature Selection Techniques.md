#ğ—£ğ˜†ğ˜ğ—µğ—¼ğ—» ğ—–ğ—¼ğ—±ğ—² ğ—œğ—ºğ—½ğ—¹ğ—²ğ—ºğ—²ğ—»ğ˜ğ—®ğ˜ğ—¶ğ—¼ğ—» for Feature Selection

## Python Libraries

import numpy as np

import pandas as pd

from sklearn.preprocessing import LabelEncoder

from sklearn.feature_selection import chi2, f_classif, mutual_info_classif, mutual_info_regression, VarianceThreshold, RFE

from sklearn.ensemble import RandomForestClassifier


#1. ğ—™ğ—²ğ—®ğ˜ğ˜‚ğ—¿ğ—² ğ—¥ğ—²ğ—¹ğ—®ğ˜ğ—¶ğ—¼ğ—»ğ˜€ğ—µğ—¶ğ—½ğ˜€

## Load your dataset

data = pd.read_csv('dataset.csv')

correlation_matrix = data.corr()

# Set a threshold to identify highly correlated features

high_corr_features = [col for col in correlation_matrix.columns if any(correlation_matrix[col] > 0.8)]


#2. ğ—–ğ—µğ—¶-ğ˜€ğ—¾ğ˜‚ğ—®ğ—¿ğ—² ğ—§ğ—²ğ˜€ğ˜ / ğ—”ğ—¡ğ—¢ğ—©ğ—” ğ—§ğ—²ğ˜€ğ˜

# Chi-square for categorical target, e.g., Loan_Approval

X, y = data.drop(columns=['Loan_Approval']), data['Loan_Approval']

y_encoded = LabelEncoder().fit_transform(y)

# Perform Chi-square test

chi2_scores, _ = chi2(X, y_encoded)

# For ANOVA with continuous targets

f_scores, _ = f_classif(X, y_encoded)


#3. ğ— ğ˜‚ğ˜ğ˜‚ğ—®ğ—¹ ğ—œğ—»ğ—³ğ—¼ğ—¿ğ—ºğ—®ğ˜ğ—¶ğ—¼ğ—»

# For classification

mutual_info = mutual_info_classif(X, y_encoded)

# For regression

# mutual_info = mutual_info_regression(X, y)


#4. ğ—©ğ—®ğ—¿ğ—¶ğ—®ğ—»ğ—°ğ—² ğ—§ğ—µğ—¿ğ—²ğ˜€ğ—µğ—¼ğ—¹ğ—±

# Set a threshold for variance (e.g., 0.01)

selector = VarianceThreshold(threshold=0.01)

X_selected = selector.fit_transform(X)


#5. ğ—¥ğ—²ğ—°ğ˜‚ğ—¿ğ˜€ğ—¶ğ˜ƒğ—² ğ—™ğ—²ğ—®ğ˜ğ˜‚ğ—¿ğ—² ğ—˜ğ—¹ğ—¶ğ—ºğ—¶ğ—»ğ—®ğ˜ğ—¶ğ—¼ğ—» (ğ—¥ğ—™ğ—˜)

# Initialize model and RFE

model = RandomForestClassifier()

rfe = RFE(estimator=model, n_features_to_select=5)

X_selected = rfe.fit_transform(X, y_encoded)

